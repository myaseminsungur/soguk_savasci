{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# filepath: /path/to/your/file.py\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-XZkorTai3cwNRvj4t3Eaap', bytes=66558, created_at=1735407580, filename='dad_joke_reasoning_samples_train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"dad_joke_reasoning_samples_test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"dad_joke_reasoning_samples_train.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAD_JOKE_REASONING_SAMPLES_TRAIN.JSONL : file-XZkorTai3cwNRvj4t3Eaap\n",
      "DAD_JOKE_REASONING_SAMPLES_TEST.JSONL : file-1fwP5mJBAVSJm1enXNHvWC\n",
      "DAD_JOKE_SAMPLES_TEST.JSONL : file-14gtA38iuJ7sJgqBmwsyNC\n",
      "DAD_JOKE_SAMPLES_TRAIN.JSONL : file-Jp47nPA2Eq2S9p7VXCEsWz\n"
     ]
    }
   ],
   "source": [
    "files = client.files.list(purpose=\"fine-tune\")\n",
    "\n",
    "for file in files:\n",
    "    print(file.filename.upper(),':',file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-2ATXiHjoeP0guwRzLG9QPjLW', created_at=1735409095, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-RuBNDg5GaMqiVIMAjwK7becX', result_files=[], seed=834169983, status='validating_files', trained_tokens=None, training_file='file-XZkorTai3cwNRvj4t3Eaap', validation_file='file-1fwP5mJBAVSJm1enXNHvWC', estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto')), type='supervised'), user_provided_suffix='cold-warrior-reasoning')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-XZkorTai3cwNRvj4t3Eaap\",\n",
    "  validation_file =\"file-1fwP5mJBAVSJm1enXNHvWC\",\n",
    "  model=\"gpt-4o-2024-08-06\",\n",
    "  suffix=\"cold-warrior-reasoning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating training file: file-XZkorTai3cwNRvj4t3Eaap and validation file: file-1fwP5mJBAVSJm1enXNHvWC\n",
      "Validating training file: file-XZkorTai3cwNRvj4t3Eaap and validation file: file-1fwP5mJBAVSJm1enXNHvWC\n",
      "Validating training file: file-XZkorTai3cwNRvj4t3Eaap and validation file: file-1fwP5mJBAVSJm1enXNHvWC\n",
      "Fine-tuning job started\n",
      "Fine-tuning job started\n",
      "Fine-tuning job started\n",
      "Fine-tuning job started\n",
      "Fine-tuning job started\n",
      "Fine-tuning job started\n",
      "Fine-tuning job started\n",
      "Fine-tuning job started\n",
      "Step 9/144: training loss=1.47\n",
      "Step 19/144: training loss=1.32\n",
      "Step 28/144: training loss=1.46\n",
      "Step 39/144: training loss=1.25\n",
      "Step 43/144: training loss=1.27\n",
      "Step 53/144: training loss=0.92\n",
      "Step 60/144: training loss=0.87, validation loss=1.02\n",
      "Step 70/144: training loss=1.04, validation loss=1.14\n",
      "Step 80/144: training loss=0.93, validation loss=1.08\n",
      "Step 90/144: training loss=0.99, validation loss=1.37\n",
      "Step 96/144: training loss=0.86, full validation loss=1.09\n",
      "Step 103/144: training loss=0.95\n",
      "Step 113/144: training loss=1.06\n",
      "Step 123/144: training loss=0.83\n",
      "Step 130/144: training loss=0.96, validation loss=1.00\n",
      "Step 140/144: training loss=0.98, validation loss=1.02\n",
      "Step 144/144: training loss=1.13, validation loss=0.97, full validation loss=1.09\n",
      "Step 144/144: training loss=1.13, validation loss=0.97, full validation loss=1.09\n",
      "Step 144/144: training loss=1.13, validation loss=0.97, full validation loss=1.09\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "while True:\n",
    "    events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-2ATXiHjoeP0guwRzLG9QPjLW\", limit=10)\n",
    "    message = events.data[0].message\n",
    "    print(message)\n",
    "    if message == \"The job has successfully completed\":\n",
    "        break\n",
    "    \n",
    "\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-4o-mini-2024-07-18:personal::AjAj8dcn\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "dad_joke_model = client.fine_tuning.jobs.retrieve(\"ftjob-34rI6p35wsPEGLjrK6R1pUCp\").fine_tuned_model\n",
    "print(dad_joke_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Dad Joke Chatbot! Type 'exit' to quit.\n",
      "Dad Joke Bot: Bir baba çocuğuna düğünde herkesin yaptığı dansa ne denir? diye sormuş.\n",
      "Dad Joke Bot: Gelin Hayatından Emin Midir.\n"
     ]
    }
   ],
   "source": [
    "def get_response(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=dad_joke_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to the Dad Joke Chatbot! Type 'exit' to quit.\")\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a dad joke expert. Create dad jokes in accordance with the user input.\"}]\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        response = get_response(messages=messages)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        print(f\"Dad Joke Bot: {response}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btk2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
